{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b4eae9951d41d19c9f5b837371833d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eron/miniconda3/envs/cuda_env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/eron/miniconda3/envs/cuda_env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe4c76fd4d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import bitsandbytes\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, TextStreamer, GenerationConfig, AutoModelForCausalLM\n",
    "sys.path.insert(0, '../..')\n",
    "from drugs.dgenerate import DRUGS, print_top_k_logits_histogram\n",
    "import drugs_conf as conf\n",
    "current_script_dir = os.getcwd()\n",
    "results_dir = os.path.join(current_script_dir, '..', 'results')\n",
    "\n",
    "model_id = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "streamer = TextStreamer(tokenizer)\n",
    "sober_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    load_in_8bit=True)\n",
    "sober_model.eval()\n",
    "torch.manual_seed(420)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sober content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST]\n",
      "\n",
      "Write an epic rap battle between William Rowe Hamilton and Lord Kelvin[/INST]\n",
      "\n",
      "[Scene: A dark and dimly lit underground rap club, the air thick with anticipation. The crowd is on the edge of their seats as two of the greatest minds in science history take the stage. William Rowe Hamilton and Lord Kelvin are about to engage in an epic rap battle.]\n",
      "\n",
      "William Rowe Hamilton:\n",
      "Yo, I'm the king of the math game,\n",
      "With equations that'll make your head spin like a flame,\n",
      "I'm the one who brought you quaternions,\n",
      "And I'll leave you in the dust, like a poor excuse for a reason.\n",
      "\n",
      "Lord Kelvin:\n",
      "Hold up, Hamilton, you ain't ready,\n",
      "I'm the one who's got the science, the facts, and the\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.load(os.path.join(results_dir, 'vergence', 'start_tensor.pt'))\n",
    "print(tokenizer.decode(input_ids[0]))\n",
    "with torch.no_grad():\n",
    "    sober_outputs = sober_model(input_ids=input_ids, past_key_values=None, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = DRUGS()\n",
    "def run_test(model, drug_type, base_name, sub_name, seed, dose_shape_callback=None, layer_begin=2, layer_end=31, dose_start=0, dose_end=3.14):\n",
    "    with torch.no_grad():\n",
    "        noise_stop_layer = layer_begin\n",
    "        microdose= dose_start\n",
    "        while noise_stop_layer < layer_end:\n",
    "            dose_shape = dose_shape_callback(noise_stop_layer)\n",
    "            drugs._set_typed_dose_shape(dose_shape[0], dose_shape[1], drug_type)\n",
    "            while microdose < dose_end:\n",
    "                torch.manual_seed(seed)\n",
    "                drugs._set_typed_dose_theta(microdose, drug_type)\n",
    "                result = model(input_ids=input_ids, past_key_values=None, output_hidden_states=True)\n",
    "                clear_output(wait=True)\n",
    "                print_top_k_logits_histogram(result.logits.to('cpu'), tokenizer, top_k=10)\n",
    "                drugs.save_trace(base_name, sub_name, noise_stop_layer, result.logits, 10, result.hidden_states, tokenizer)            \n",
    "                microdose += 0.05\n",
    "            noise_stop_layer = noise_stop_layer + 1 #if noise_stop_layer < 4 else noise_stop_layer + 4\n",
    "            microdose=dose_start\n",
    "\n",
    "def layerwise_callback(at_layer):\n",
    "    return([{'depth': (at_layer-1.1)/32, 'peakratio': 0},\n",
    "            {'depth': (at_layer-1)/32, 'peakratio': 1},\n",
    "            {'depth': (at_layer+1)/32, 'peakratio' : 1},\n",
    "            {'depth': (at_layer+1.1)/32, 'peakratio' : 0}], 'ceil')\n",
    "\n",
    "def fullstack_calback(at_layer):\n",
    "    return([{'depth': -1, 'peakratio': 1},\n",
    "            {'depth': (at_layer+1.1)/32, 'peakratio': 0}], 'ceil')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use DRÂµGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- \n",
      "\n",
      "#########                                                                                                      flow                    2.05%\n",
      "##########                                                                                                  feature                    2.09%\n",
      "##########                                                                                                     duty                    2.12%\n",
      "############                                                                                                      c                    2.52%\n",
      "############                                                                                                   cred                    2.56%\n",
      "##################                                                                                                g                    3.75%\n",
      "#####################                                                                                           cre                    4.49%\n",
      "############################                                                                                    dec                    5.81%\n",
      "###################################                                                                          steady                    7.40%\n",
      "####################################################################################################         energy                   20.59%\n",
      "---::::energy:::   \n",
      "\n",
      "saving: /home/eron/drugs/drugs/../experiments/results/Hamilton_V_dose/single_layer/injection_depth_30_(0A_0Q_0K_177V)-dose.msgpack\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "model = drugs.inject(sober_model, tokenizer=tokenizer)\n",
    "print_top_k_logits_histogram(sober_outputs.logits[:,:,:].to('cpu'), tokenizer=tokenizer)\n",
    "microdose=0\n",
    "noise_stop_layer = 2\n",
    "seed = 420\n",
    "\n",
    "run_test(model, 'A', f\"Hamilton_A_dose\", \"single_layer\",  seed, layerwise_callback)\n",
    "drugs.set_A_dose_theta(0)\n",
    "run_test(model, 'Q', f\"Hamilton_Q_dose\", \"single_layer\", seed, layerwise_callback)\n",
    "drugs.set_Q_dose_theta(0)\n",
    "run_test(model, 'K', f\"Hamilton_K_dose\", \"single_layer\", seed, layerwise_callback)\n",
    "drugs.set_K_dose_theta(0)\n",
    "run_test(model, 'V', f\"Hamilton_V_dose\", \"single_layer\", seed, layerwise_callback)\n",
    "drugs.set_V_dose_theta(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- \n",
      "\n",
      "##########################                                                                                Stein                    0.39%\n",
      "############################                                                                               Stim                    0.41%\n",
      "############################                                                                               vast                    0.42%\n",
      "#############################                                                                               cup                    0.43%\n",
      "#########################################                                                                   Chi                    0.60%\n",
      "##############################################                                                            fluid                    0.68%\n",
      "##############################################                                                               of                    0.68%\n",
      "#################################################                                                           hre                    0.72%\n",
      "##############################################################                                             ilar                    0.91%\n",
      "####################################################################################################       rane                    1.46%\n",
      "---::::rane:::   \n",
      "\n",
      "saving: /home/eron/drugs/drugs/../experiments/results/Hamilton_V_dose/fullstack/injection_depth_30_(0A_0Q_0K_177V)-dose.msgpack\n"
     ]
    }
   ],
   "source": [
    "drugs.set_V_dose_theta(0)\n",
    "#run_test(model, 'A', \"Hamilton_A_dose\", \"fullstack\", seed, fullstack_calback)\n",
    "drugs.set_A_dose_theta(0)\n",
    "#run_test(model, 'Q', \"Hamilton_Q_dose\", \"fullstack\", seed, fullstack_calback)\n",
    "drugs.set_Q_dose_theta(0)\n",
    "run_test(model, 'K', \"Hamilton_K_dose\", \"fullstack\", seed, fullstack_calback)\n",
    "drugs.set_K_dose_theta(0)\n",
    "run_test(model, 'V', \"Hamilton_V_dose\", \"fullstack\", seed, fullstack_calback)\n",
    "drugs.set_V_dose_theta(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
